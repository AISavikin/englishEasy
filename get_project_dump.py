import os
import fnmatch
from datetime import datetime
import mimetypes


def ask_path(prompt, default="."):
    value = input(f"{prompt} [{default}]: ").strip()
    return value if value else default


def ask_yes_no(prompt, default="n"):
    value = input(f"{prompt} (y/n) [{default}]: ").strip().lower()
    if value == "":
        value = default
    return value == "y"


def ask_list(prompt, default=""):
    value = input(f"{prompt} (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é) [{default}]: ").strip()
    if not value:
        value = default
    return [v.strip() for v in value.split(",") if v.strip()]


def ask_int(prompt, default=0):
    value = input(f"{prompt} [{default}]: ").strip()
    if not value:
        return default
    try:
        return int(value)
    except ValueError:
        print(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —á–∏—Å–ª–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {default}")
        return default


def get_language_from_extension(filename):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é —Ñ–∞–π–ª–∞"""
    extension_map = {
        '.py': 'python',
        '.js': 'javascript',
        '.jsx': 'javascript',
        '.ts': 'typescript',
        '.tsx': 'typescript',
        '.java': 'java',
        '.c': 'c',
        '.cpp': 'cpp',
        '.h': 'c',
        '.hpp': 'cpp',
        '.cs': 'csharp',
        '.go': 'go',
        '.rs': 'rust',
        '.rb': 'ruby',
        '.php': 'php',
        '.html': 'html',
        '.htm': 'html',
        '.css': 'css',
        '.scss': 'scss',
        '.sass': 'sass',
        '.less': 'less',
        '.sql': 'sql',
        '.json': 'json',
        '.xml': 'xml',
        '.yaml': 'yaml',
        '.yml': 'yaml',
        '.toml': 'toml',
        '.ini': 'ini',
        '.cfg': 'ini',
        '.sh': 'bash',
        '.bash': 'bash',
        '.zsh': 'bash',
        '.ps1': 'powershell',
        '.md': 'markdown',
        '.txt': 'text',
        '.csv': 'csv',
        '.tsv': 'tsv',
        '.svg': 'xml',
        '.rst': 'restructuredtext',
        '.tex': 'latex',
        '.r': 'r',
        '.swift': 'swift',
        '.kt': 'kotlin',
        '.kts': 'kotlin',
        '.dart': 'dart',
        '.lua': 'lua',
        '.pl': 'perl',
        '.pm': 'perl',
        '.tcl': 'tcl',
        '.vim': 'vim',
        '.dockerfile': 'dockerfile',
        '.env': 'properties',
        '.properties': 'properties',
        '.gitignore': 'gitignore',
        '.dockerignore': 'gitignore',
        '.npmignore': 'gitignore',
    }

    _, ext = os.path.splitext(filename.lower())
    if ext in extension_map:
        return extension_map[ext]

    # –ü–æ–ø—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ MIME-—Ç–∏–ø—É
    mime_type, _ = mimetypes.guess_type(filename)
    if mime_type:
        if mime_type.startswith('text/'):
            return 'text'
        elif mime_type == 'application/json':
            return 'json'
        elif mime_type == 'application/xml':
            return 'xml'

    return 'text'


def is_binary_file(filepath):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –±–∏–Ω–∞—Ä–Ω—ã–º"""
    try:
        with open(filepath, 'tr', encoding='utf-8') as f:
            f.read(1024)
        return False
    except:
        return True


def is_excluded(path: str, exclude_masks):
    filename = os.path.basename(path)
    for mask in exclude_masks:
        if fnmatch.fnmatch(filename, mask):
            return True
    return False


def build_tree(start_path: str, include_hidden: bool, exclude_masks) -> str:
    tree_lines = []

    for root, dirs, files in os.walk(start_path):
        if not include_hidden:
            dirs[:] = [d for d in dirs if not d.startswith('.')]
            files = [f for f in files if not f.startswith('.')]

        dirs[:] = [d for d in dirs if not is_excluded(d, exclude_masks)]
        files = [f for f in files if not is_excluded(f, exclude_masks)]

        level = root.replace(start_path, "").count(os.sep)
        indent = "    " * level
        tree_lines.append(f"{indent}- {os.path.basename(root)}/")

        sub_indent = "    " * (level + 1)
        for file in files:
            tree_lines.append(f"{sub_indent}- {file}")

    return "\n".join(tree_lines)


def collect_files(start_path: str, include_hidden: bool, exclude_masks, max_file_size_mb=1) -> list:
    """–°–æ–±–∏—Ä–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π"""
    files_data = []
    max_size_bytes = max_file_size_mb * 1024 * 1024

    for root, dirs, files in os.walk(start_path):
        if not include_hidden:
            dirs[:] = [d for d in dirs if not d.startswith('.')]
            files = [f for f in files if not f.startswith('.')]

        dirs[:] = [d for d in dirs if not is_excluded(d, exclude_masks)]
        files = [f for f in files if not is_excluded(f, exclude_masks)]

        for file in files:
            file_path = os.path.join(root, file)
            rel_path = os.path.relpath(file_path, start_path)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            try:
                file_size = os.path.getsize(file_path)
                if file_size > max_size_bytes:
                    print(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º {rel_path} (—Ä–∞–∑–º–µ—Ä {file_size // 1024}KB > {max_file_size_mb}MB)")
                    continue
            except OSError:
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –±–∏–Ω–∞—Ä–Ω—ã–π –ª–∏ —Ñ–∞–π–ª
            if is_binary_file(file_path):
                print(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–∏–Ω–∞—Ä–Ω—ã–π —Ñ–∞–π–ª: {rel_path}")
                continue

            language = get_language_from_extension(file)

            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
            except UnicodeDecodeError:
                try:
                    with open(file_path, "r", encoding="cp1251") as f:
                        content = f.read()
                except Exception as e:
                    content = f"<<–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e} (–ø—Ä–æ–±–æ–≤–∞–ª–∏ utf-8 –∏ cp1251)>>"
            except Exception as e:
                content = f"<<–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}>>"

            files_data.append({
                "path": rel_path,
                "language": language,
                "content": content,
                "size": file_size
            })

    return files_data


def calculate_tokens_approximate(content):
    """–ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤ (–æ—á–µ–Ω—å –≥—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞)"""
    # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: 1 —Ç–æ–∫–µ–Ω ‚âà 4 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    # –î–ª—è —Ä—É—Å—Å–∫–æ–≥–æ/–∫–æ–¥–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥—Ä—É–≥–∞—è –ø—Ä–æ–ø–æ—Ä—Ü–∏—è
    chars = len(content)
    words = len(content.split())
    return {
        "chars": chars,
        "words": words,
        "tokens_approx": chars // 4  # –û—á–µ–Ω—å –≥—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞
    }


def build_toc(files_data):
    """–°–æ–∑–¥–∞–µ—Ç –æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ —Å —è–∫–æ—Ä–Ω—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏"""
    toc_lines = ["## üìë –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤\n"]

    for i, file_info in enumerate(files_data, 1):
        anchor = f"file-{i:04d}"
        toc_lines.append(f"{i}. [{file_info['path']}](#{anchor})")

    return "\n".join(toc_lines)


def save_markdown_enhanced(start_path: str, output_file: str, include_hidden: bool, exclude_masks, max_file_size_mb=1):
    """–°–æ–∑–¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π Markdown —Ñ–∞–π–ª"""
    print("–°—Ç—Ä–æ—é –¥–µ—Ä–µ–≤–æ –ø—Ä–æ–µ–∫—Ç–∞...")
    tree = build_tree(start_path, include_hidden, exclude_masks)

    print("–°–æ–±–∏—Ä–∞—é —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤...")
    files_data = collect_files(start_path, include_hidden, exclude_masks, max_file_size_mb)

    if not files_data:
        print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –¥–∞–º–ø!")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_files = len(files_data)
    total_chars = sum(f["size"] for f in files_data)
    stats = calculate_tokens_approximate("\n".join([f["content"] for f in files_data]))

    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    metadata = f"""# üìÅ –î–∞–º–ø –ø—Ä–æ–µ–∫—Ç–∞: {os.path.basename(os.path.abspath(start_path))}

## üìä –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ

- **–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **–ò—Å—Ö–æ–¥–Ω—ã–π –ø—É—Ç—å:** `{os.path.abspath(start_path)}`
- **–í–∫–ª—é—á–µ–Ω–æ —Ñ–∞–π–ª–æ–≤:** {total_files}
- **–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä:** {total_chars // 1024 if total_chars > 1024 else total_chars} {'KB' if total_chars > 1024 else 'bytes'}
- **–ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤:** {stats['tokens_approx']:,} (–æ—Ü–µ–Ω–∫–∞)
- **–°–∏–º–≤–æ–ª–æ–≤:** {stats['chars']:,}
- **–°–ª–æ–≤:** {stats['words']:,}
- **–í–∫–ª—é—á–µ–Ω—ã —Å–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã:** {'–î–∞' if include_hidden else '–ù–µ—Ç'}
- **–ò—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ –º–∞—Å–∫–∏:** `{', '.join(exclude_masks)}`
- **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞:** {max_file_size_mb} MB

---
"""

    # –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ
    toc = build_toc(
        files_data) if total_files <= 100 else "## üìë –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤\n\n*–û–≥–ª–∞–≤–ª–µ–Ω–∏–µ —Å–∫—Ä—ã—Ç–æ –∏–∑-–∑–∞ –±–æ–ª—å—à–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤ (>100)*\n"

    # –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤
    files_content = []
    for i, file_info in enumerate(files_data, 1):
        anchor = f"file-{i:04d}"
        file_header = f'\n\n<a id="{anchor}"></a>\n## üìÑ `{file_info["path"]}`\n\n'
        file_header += f"**–Ø–∑—ã–∫:** `{file_info['language']}`  \n"
        file_header += f"**–†–∞–∑–º–µ—Ä:** {file_info['size']} bytes\n\n"

        code_block = f"```{file_info['language']}\n{file_info['content']}\n```\n"
        files_content.append(file_header + code_block + "---")

    with open(output_file, "w", encoding="utf-8") as f:
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        f.write(metadata + "\n")

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ
        f.write(toc + "\n\n")

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–µ—Ä–µ–≤–æ –ø—Ä–æ–µ–∫—Ç–∞
        f.write("## üå≥ –î–µ—Ä–µ–≤–æ –ø—Ä–æ–µ–∫—Ç–∞\n\n")
        f.write("```\n" + tree + "\n```\n\n")
        f.write("---\n\n")

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤
        f.write("# üìÑ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤\n\n")
        f.write("\n".join(files_content))

    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –£–ª—É—á—à–µ–Ω–Ω—ã–π Markdown —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_file}")
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {total_files} —Ñ–∞–π–ª–æ–≤, ~{stats['tokens_approx']:,} —Ç–æ–∫–µ–Ω–æ–≤")


def save_json_alternative(start_path: str, output_file: str, include_hidden: bool, exclude_masks):
    """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ (–¥–ª—è –º–∞—à–∏–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏)"""
    import json

    print("–°–æ–±–∏—Ä–∞—é –¥–∞–Ω–Ω—ã–µ –¥–ª—è JSON...")
    files_data = collect_files(start_path, include_hidden, exclude_masks)

    project_data = {
        "metadata": {
            "project_name": os.path.basename(os.path.abspath(start_path)),
            "created_at": datetime.now().isoformat(),
            "source_path": os.path.abspath(start_path),
            "include_hidden": include_hidden,
            "exclude_masks": exclude_masks,
            "total_files": len(files_data)
        },
        "files": files_data
    }

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(project_data, f, ensure_ascii=False, indent=2)

    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! JSON —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_file}")


if __name__ == "__main__":
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë   üöÄ –£–õ–£–ß–®–ï–ù–ù–´–ô –î–ê–ú–ü–ï–† –ü–†–û–ï–ö–¢–û–í          ‚ïë
‚ïë   –¥–ª—è LLM –∏ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞                 ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)

    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    start_path = ask_path("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É", ".")
    output_file = ask_path("–í–≤–µ–¥–∏—Ç–µ –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞", "project_dump.md")
    include_hidden = ask_yes_no("–í–∫–ª—é—á–∞—Ç—å —Å–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã?")

    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    exclude_masks = ask_list("–ú–∞—Å–∫–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è",
                             "*.pyc, __pycache__, *.sqlite3, migrations, node_modules, .git, .env, *.log, *.tmp, *.temp, *.o, *.obj, *.exe, *.dll, *.so, *.dylib, *.class, *.jar, *.war, *.ear, *.zip, *.tar, *.gz, *.rar, *.7z, *.pdf, *.doc, *.docx, *.xls, *.xlsx, *.ppt, *.pptx, *.jpg, *.jpeg, *.png, *.gif, *.bmp, *.tiff, *.ico, *.mp3, *.mp4, *.avi, *.mov, *.wmv")

    # –í—ã–±–æ—Ä —Ñ–æ—Ä–º–∞—Ç–∞
    print("\nüéØ –í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞:")
    print("  1. Markdown (–ª—É—á—à–µ –¥–ª—è LLM, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π)")
    print("  2. JSON (–ª—É—á—à–µ –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏)")

    format_choice = input("–í—ã–±–æ—Ä [1]: ").strip()
    if format_choice == "2":
        use_json = True
    else:
        use_json = False

    if not use_json:
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ü–∏–∏ –¥–ª—è Markdown
        max_file_size = ask_int("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ MB (0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)", 1)

        print("\n" + "=" * 50)
        print("‚öôÔ∏è  –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Markdown:")
        print(f"   ‚Ä¢ –ü—É—Ç—å: {os.path.abspath(start_path)}")
        print(f"   ‚Ä¢ –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {output_file}")
        print(f"   ‚Ä¢ –°–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã: {'–î–∞' if include_hidden else '–ù–µ—Ç'}")
        print(f"   ‚Ä¢ –ò—Å–∫–ª—é—á–µ–Ω–∏—è: {exclude_masks}")
        print(f"   ‚Ä¢ –ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {max_file_size} MB")
        print("=" * 50 + "\n")

        print("–°–æ–±–∏—Ä–∞—é –¥–∞–Ω–Ω—ã–µ...\n")
        save_markdown_enhanced(start_path, output_file, include_hidden, exclude_masks, max_file_size)
    else:
        print("\n–°–æ–±–∏—Ä–∞—é –¥–∞–Ω–Ω—ã–µ –≤ JSON...\n")
        save_json_alternative(start_path, output_file.replace('.md', '.json'), include_hidden, exclude_masks)

    print("\n‚ú® –î–∞–º–ø —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω! –ì–æ—Ç–æ–≤ –∫ –∑–∞–≥—Ä—É–∑–∫–µ –≤ LLM.")